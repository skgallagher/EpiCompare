---
documentclass: jss
author:
  - name: Shannon K. Gallagher
    affiliation: |
      | Biostatistics Research Branch
      | National Institute of Allergy 
      | and Infectious Diseases
    # use this syntax to add text on several lines
    address: |
      | 5603 Fishers Lane
      | Rockville, MD 20852
    email: \email{shannon.gallagher@nih.gov}
    url: http://skgallagher.github.io
  - name: Benjamin LeRoy
    affiliation: |
      | Dept. of Statistics & Data Science
      | Carnegie Mellon University
    address: |
      | 5000 Forbes Ave.
      | Pittsburgh, PA 15213
    email: \email{bpleroy@andrew.cmu.edu}
    url:  https://benjaminleroy.github.io/

title:
  formatted: "Time invariant analysis of epidemics with \\pkg{EpiCompare}"
  # If you use tex in the formatted title, also supply version without
  plain:     "Time invariant analysis of epidemics with EpiCompare"
  # For running headers, if needed
  short:     "\\pkg{EpiCompare}"
abstract: >
  We present \pkg{EpiCompare}, an \proglang{R} package that suppliments and enhance current infectious disease modeling analysis pipelines as well as to encourage comparisons across these pipelines. A major contribution of this work is the set of novel \textit{time-invariate} tools for model and epidemic comparisons - including time-invariate prediction bands. \pkg{EpiCompare} encorporates \proglang{R}'s \textit{tidy} coding style to aid it rapid and easy use. This paper provides an overview of both the tools in and intuition behind \pkg{EpiCompare} and a thorough demonstrating of the tools through a detailed example of a full data analysis pipeline.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
preamble: >
  \usepackage{amsmath}
  \usepackage{amsthm}
output: 
  rticles::jss_article:
    number_sections: TRUE     #added argument option 
    citation_package: "natbib"  #All my citations use biblatex, not natbib. 
classoption: shortnames
biblio-style: jss      #Listed to use in JSS Instructions for Authors, but not in template by default. 
bibliography: EpiCompare.bib  #Also not included in template by default. 
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{xcolor}
  - \usepackage{rotating}
---




```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')
options(kableExtra.latex.load_packages = FALSE)


knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      fig.align = "center",
                      echo=TRUE, warning=FALSE, message=FALSE,
                      fig.pos = "H",
                      cache = TRUE)

devtools::load_all("../../")

```

\newcommand{\shannon}[1]{\textcolor{orange}{#1}}
\newcommand{\ben}[1]{\textcolor{violet}{#1}}

\newtheorem{theorem}{Theorem}


# Introduction {short-title="Intro" #sec:intro}

The recent (and on-going) COVID-19 global pandemic has galvanized public interest in understanding more about infectious disease modeling and has highlighted the usefulness of research in the area of infectious disease epidemiology. Infectious diseases inflict enormous burdens on the world: millions of lives lost and trillions of dollars spent yearly. Infectious disease models typically attempt to do one or more of the following: 1) predict the spread of current and future epidemics \citep[e.g. flu prediction][]{Biggerstaff2016}, 2) analyze past and current epidemics to increase scientific knowledge \citep[e.g. historical measle outbreaks][]{Neal2004}, and 3) forecast or project epidemic scenarios under pre-specified parameters \citep[e.g.][]{ferguson2020}. At the same time, descriptive statistics and visualizations from universities, many branches and levels of government, and news organizations  are an important first step of the process \citep{dong2020,cdc-covid-tracker2021,wp-covid-tracker2021} .

With the many visualization and exploratory tools, models and modeling paradigms, and reviews and comparisons in the literature and through the MIDAS (Models of Infectious Disease Agent Study) network \citep{midasnetwork2021}, this field has a lot of devices to aid an individual practitioner decide the correct approach.  For example,\proglang{R} packages such as \pkg{surveillance}, \pkg{EpiModel}, and \pkg{pomp} have all made significant steps in standardizing the flow of the data analysis pipeline for epidemic modeling through digitizing data sets, making accessible statistical models, and providing a plethora of educational material for both coding novices and experts alike \citep{surveillance2017,Jenness2018,King2016}.

At the same time, analysis packages often only address a specific portion of the analysis pipeline, for instance focusing on certain types of models. Modeling tools, which usually require learning package-specific syntax, often don't provide easy ways to compare and assess their models on new data. Moreover, exploring and modeling epidemics require transforming and \textit{tidying} data in different ways. To fill these gaps, we present our \proglang{R} package \pkg{EpiCompare}. Our package's primary focus is to aid and advance research in the area of comparison and assessment of epidemic and epidemiological models. In Figure \ref{fig:pipeline}, we illustrate the data analysis pipeline of infectious diseases  as 1) data pre-processing, 2) exploratory data analysis (EDA), 3) modeling and simulating, 4) post-processing, and 5) comparison and assessment; where each previous part of the pipeline influences the next. \pkg{EpiCompare} provides tools to aids practitioners in all areas of this pipeline.


<!-- # old draft
The recent (and currently on-going) COVID-19 global pandemic has galvanized public interest in understanding more about infectious disease modeling and has highlighted the usefulness of research in the area of infectious disease epidemiology. Infectious disease models typically attempt to do one or more of the following: 1) predict the spread of current and future epidemics \citep[e.g. flue prediction][]{Biggerstaff2016}, 2) analyze past and current epidemics to increase scientific knowledge \citep[e.g. historical measle outbreaks][]{Neal2004}, and 3) forecast or project epidemic scenarios under pre-specified parameters \citep[e.g. ...][]{}. The COVID-19 pandemic highlights how all three goals are important both separately and taken as a whole.  Infectious diseases inflict enormous burdens on the world: millions of lives lost and trillions of dollars spent yearly.  Correctly analyzing and addressing these issues aids in prevention and mitigation of future outbreaks. \shannon{really like this paragraph}


The current epidemic of COVID-19 also highlights that infectious disease  models are only one piece of the overall analysis pipeline. University based resources like John Hopkins' and government numerical dashboards (across all levels of government) during the COVID-19 epidemic remind us that descriptive statistics and visualization can be a important first step in the process (multiple \cite{}?).} \shannon{add comment about NYT or something} Still, rightly so, a large amount of theoretical work goes into modeling epidemics, with different models focusing at the individual / agent level, network structure or just aggregate flows (review paper \cite{}?). All placing individuals / proportions of the populations into different states (e.g. suspectible, exposed, infected, recovered, etc.). With all these models, review and comparison papers in the literature and through MIDAS (Models of Infectious Disease Agent Study) Control Center helps the individual practitioner decide the correct approach. \shannon{along with expertise from healthcare professionals...}

At the same time, analysis packages often only address a portion of the analysis pipeline. Modeling tools often don't provide easy ways to compare and assess their models on new data. Moreover, exploring and modeling epidemics require transforming and \textit{tidying} data in different ways. To fill these gaps, we present our our \proglang{R} package \pkg{EpiCompare}. Our package's primary focus is to aid and advance research in the area of comparison and assessment of epidemic \& epidemiological models. In Figure \ref{fig:pipeline}, we illustrate the data analysis pipeline of infectious diseases  as 1) data pre-processing, 2) exploratory data analysis (EDA), 3) modeling and simulating, 4) post-processing, and 5) comparison and assessment; where each previous part of the pipeline influences the next. \pkg{EpiCompare} provides tools to aids practitioners in all areas of this pipeline. 
-->

\begin{figure}[!ht]
    \centering
    \includegraphics[width = 1\textwidth]{images/pipeline1.png}
    \caption{An idealized epidemiological data analysis pipeline.}
    \label{fig:pipeline}
\end{figure}

\pkg{EpiCompare} also emphasizes the value of analyzing epidemics in a \textit{time-invariant} way. Epidemics, despite by definition being a process that evolves over time, often need to be compared in a way not constrained to initial times or time scales to understand the processes at play. Additionally, many tools designed to examine the quantity of the population in each epidemic state (for example: quantity of Susceptible vs Infectious vs Recovered individuals) don't always as intelligently capture the natural connections between the proportion of individuals in these states. \shannon{I don't quite understand this.  Is this because of underreporting?  If so I'm not sure how EpiCompare helps us here.} Tools in \pkg{EpiCompare} give the user the ability to extend their toolkit to evaluate epidemics within a time-invariant lens. The goal of \pkg{EpiCompare} is not to supplant existing infectious disease modeling tools and software but, rather, is a concerted effort to create standard and fair comparisons among models developed for disease outbreaks and outbreak data.

This paper is broken up into the following sections, section \ref{sec:time-invariant} motivates and showcases tools of time-invariant analysis,  section \ref{sec:overview} presents an outline of how \pkg{EpiCompare} aids a practitioner in every step of the pipeline and section \ref{sec:tour} provides a thorough demonstrating of the tools through a detailed example of a full data analysis pipeline.


# Motivation and tools for time-invariant analysis {short-title="Time-invariant" #sec:time-invariant}

Epidemics can be difficult to compare to one another due to differences in diseases, locations, or population behaviors, or times.  In \pkg{EpiCompare}, we emphasize comparisons between epidemics adjusting for the last component, time.  Time-invariant analysis is beneficial because by adjusting for the unit of infection rate, we can focus on the "lifetime" of an epidemic, a view that is concerned more with the number of lives affected than as opposed to any specific time constraint.    Time-invariant analysis is also beneficial when there are gaps in time between occurrences of outbreaks of a similar nature in different geographic regions.  Finally, time-invariant analysis is beneficial because many studies talk about a period of ``exponential growth'' of the number of outbreaks \citep{chowell2007,wallinga2007generation,forsberg2008}.

Time-invariant analysis, as it appears in \pkg{EpiCompare} solves the above issues by observing functionals which attempt to capture the general shape of the epidemic with respect to the proportion of the population in each epidemic state.  This allows us to compare scenarios as different as, for instance as a decades-long outbreak HIV in the US compared to a 10 day outbreak of norovirus on a cruise ship.  Moreover, this tool avoids the need for choosing a 'beginning' $t_0$ or 'end' $t_F$ of an epidemic, choices \cite{gallagher2020} show that can heavily influence, for example,  estimates of peak infection height or the reproduction number $R_0$.


## $R_0$  and time-invariant analysis {short-title="r0" #r0}

 By definition, $R_0$ is the number of expected secondary infections when a primary infection is introduced to a susceptible population.  $R_0$ is also, maybe, the most famous \textit{time-invariant} numerical summary of an epidemic, which allows epidemics to be compared to one another in both different time and geographic scales. For example, $R_0$ for Covid-19 is estimated to be between 2-3, seasonal influenza between 1.2-2, and modern measles outbreaks as large as 12 \citep{midas2020,biggerstaff2014,namee2018}.

Estimators for $R_0$ are dependent on the epidemic modeling framework, which consists of which states an individual can occupy (e.g. susceptible, infectious, recovered) and a description of how individuals move from one state to the next over time (see \cite{hethcote1994}).  A common epidemic modeling framework is the SIR model, originally introduced by @kermack1927.  Transitions from one state to the next are defined by a series of ordinary differential equations, where $N$ is the (fixed) total number individuals, $\beta$ is the rate of infection, and $\gamma$ is rate of recovery,
\begin{align}\label{eq:sir-ode}
      S^\prime(t) &= -\frac{\beta S(t)I(t)}{N} \\
      I^\prime(t) &= \frac{\beta S(t)I(t)}{N} - \gamma I(t) \nonumber\\
      R^\prime(t) &= \gamma I(t) \nonumber.
  \end{align}
From this, $\hat{R}_0 = \frac{\hat{\beta}}{\hat{\gamma}}$, the ratio of the estimated infection rate compared to the estimated recovery rate.


With regards to traditional epidemic $state$ vs. $time$ plots, $R_0$ is difficult to visualize, especially with respect from one epidemic to another. For example, consider the scenarios where the first epidemic is generated from a SIR model with $(S(0) = 990, I(0) = 10)$, $\beta_1 = 0.3$ and $\gamma_1 = 0.15$, and the second epidemic is generated from a SIR model with $(S(0) = 990, I(0) = 10)$, $\beta_2 = 0.24$ and $\gamma_1 = 0.12$ over the first 15 days.  Both epidemics have the same value of $R_0 = \beta_1/ \gamma_1 = \beta_2 / \gamma_2 = 2$.  The epidemic trajectories are shown in the $state$ vs. time plots in Figure \ref{fig:different-scales-standard}.  At a glance, we may assume that Model 1 has a larger $R_0$ than Model 2 because the peak of infection occurs more quickly than in Model 2.  On the other hand, we may think Model 2 has a larger $R_0$ because we may think the number of infections in that model has not yet peaked at time 15.


```{r echo = FALSE}
devtools::load_all()
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)
library(ggplot2)
set.seed(1)

theme_set(theme_bw(base_size = 24))
```


```{r echo = FALSE, fig.cap = "\\label{fig:different-scales-standard}Example of two epidemics with different $\\beta$ and $\\gamma$ paremeters but the same initial reproduction number $R_0$ = 2.  Both plots are generated from models with $N= 1000$ individuals with $S(0) = 990$ and $I(0) = 10$."  }
set.seed(1225)
theme_set(theme_bw(base_size = 24))

beta1 <- .8
gamma1 <- .4
scale <- .8
sir1 <- simulate_SIR_agents(n_sims = 100, n_time_steps = 40,
                            beta = beta1, gamma = gamma1,
                            init_SIR = c(990, 10, 0)) %>%
  group_by(sim) %>%
  agents_to_aggregate(states = c(tI, tR)) %>%
  group_by(t) %>%
  summarize(S = mean(X0), I = mean(X1), R = mean(X2),
            .groups = "drop") %>%
  mutate(type = "Model 1")

sir2 <- simulate_SIR_agents(n_sims = 100, n_time_steps = 40,
                            beta = beta1 * scale, gamma = gamma1 * scale,
                            init_SIR = c(990, 10, 0)) %>%
  group_by(sim) %>%
    agents_to_aggregate(states = c(tI, tR)) %>%
  group_by(t) %>%
  summarize(S = mean(X0), I = mean(X1), R = mean(X2),
            .groups = "drop") %>%
  mutate(type = "Model 2")

df <- bind_rows(sir1, sir2)

df_long <- df %>%
         tidyr::pivot_longer(cols = c(S, I, R))  %>%
  mutate(name = factor(name, levels = c("S", "I", "R")))

ggplot(data = df_long,
       aes(x = t, y = value, col = type)) + 
  facet_wrap(~name, ncol = 1, scales = "free") +
  geom_point() +
  scale_color_manual(values = c("red", "blue"), name = "Epidemic") +
  labs(x = "Time",
       y = "# in state",
       title = latex2exp::TeX("Comparing two epidemics over first 15 days with same $R_0$")) +
  coord_cartesian(xlim = c(0, 15))
```
However, when we plot the trajectories as a single curve using the ternary plot in the time-invariant view, we immediately see a different story.  In this time-invariant view in Fig. \ref{fig:different-scales-tern}, the points seem to overlap and form the same trajectory.  Now it seems to be that Model 2 is following the same trajectory as Model 1 but is not as far along in the infection process.  We can see there is something fundamentally linking these two different epidemics, and this fundamental link turns out to be $R_0$.

More formally, let two Kermack and McKendrick  SIR models(see Eq.\eqref{eq:sir-ode} )  be denoted $(S_1(t), I_1(t), R_1(t))$ and $(S_2(t), I_2(t), R_2(t))$, respectively, for $t > 0$. Assume both models have initial values $(S(0), I(0), R(0))$.  Let $R_0 = \frac{\beta_1}{\gamma_1} = \frac{\beta_2}{\gamma_2}$ where $\beta_i$ and $\gamma_i$ are the average infection rate and recovery rate, respectively, for SIR model $i=1, 2$.  Equivalently, $\beta_2 = a \beta_1$ if and only if $\gamma_2 = a \gamma_1$ for some $a > 0$. 

\begin{theorem}\label{thm:sir-scale}
Let there be two SIR models as described above.  Then for all $t > 0$ there exists an $s>0$ such that $(S_1(t), I_1(t), R_1(t)) = (S_2(s), I_2(s), R_2(s))$.  Moreover, $s = \frac{1}{a}t$.
\end{theorem}

The proof of Theorem \ref{thm:sir-scale} relies on a fairly recent result from \cite{Harko2014} and is shown in detail in Proof \ref{proof:thm}.  The consequence of Theorem \ref{thm:sir-scale} is that for two SIR models that have the same initial percent of individuals in each state and $R_0$ then for every point on the epidemic path of the first SIR model is also a point on the epidemic path of the second SIR model. Taking the sample simulations from Fig. \ref{fig:different-scales-standard}, Fig. \ref{fig:different-scales-tern} presents these two models in a ternary plot.  This means with our time-invariant ternary plot, that at a glance, we can tell if two epidemics have different values of $R_0$.


```{r warning = FALSE, message = FALSE, echo = FALSE, fig.cap = "\\label{fig:different-scales-tern}Example of two epidemics with different $\\beta$ and $\\gamma$ paremeters but the same initial reproduction number $R_0$ = 2.  Both plots are generated from models with $N= 1000$ individuals with $S(0) = 990$ and $I(0) = 10$.  These are plotted in the time-invariant view, where we can see the number of susceptible, infectious, and recovered."}
ggplot(data = df %>%
         filter(t <= 15)) +
  geom_point(aes(x = S, y = I, z = R,
                     col = type)) +
    coord_tern() + 
  theme_sir() +
  scale_color_manual(values = c("red", "blue"), name = "Epidemic") 
```


## Beyond the Kermack and McKendrick SIR models


Although the result of Theorem \ref{thm:sir-scale} allows for easy visual comparison of $R_0$ in Kermack SIR models, it does require stringent assumptions of homogeneity of behavior in populations.  The use of visualizing epidemics in a time-invariant lens via ternary plots extends beyond those of models that follow the ODEs in the Kermack-McKendrick equations.  Any model with S, I, and R states can be visualized with ternary plots, regardless of birth and death dynamics and regardless of homogeneity of individual behavior.  We can use ternary plots to compare the spread of a disease for groups within a population without time as a confounding factor.  We show an example of this in a later section.




Moreover, time-invariant analysis is also useful for epidemic models with more than three epidemic states. The constraints in three dimensions that are met with the SIR model (there are three epidemic states and for each time step, the sum of total number of individuals in each state is the population size at that time) represents a space of 3d simplices, and the ternary plot specifically represents these simplices, after scaling the values in each state as proportions of the total population at that time (ternary plots are known as a 3d unit simplex due to it's scaling). This same scaling for larger models (i.e. with more states) can be done onto different simplexes. In this package we present tools to help compare models (mostly through simulations).  \pkg{EpiCompare}'s tools permits comparisons of $d$-dimensional objects by projecting them into ($d-1$)-dimensional space.

 Even though higher dimensional models may not be able to visualized simply, we provide a number of tools to aid in the comparison of models and epidemics. The first of which uses multiple simulations under specific model parameters to assess the \shannon{variability?} bairabilty of the model fit. In \pkg{EpiCompare}, we provide ways to create prediction regions for a `true' epidemic under a fully specified model. These regions require representing multi-dimensional structures for functions to completely contain epidemics.  \pkg{EpiCompare} treats these simulations and epidemics as \textit{filamental} objects -- \shannon{need a description for filamental, Ben feel free to change} where not only the outbreak trajectory points are important but also their form which can be considered a function. \shannon{could be useful to have a picture/example here? like  three curves and 2 metrics one where closer under a pointwise distance and the other closer in filamental distance? I'll sketch up an idea unless you have something in your proposal already}
 
 We extend off of papers like \citet{Dalmasso2019a} to create these bands. These high dimensional bands allow the user to assess if the true epidemic is within the band (thereby assessing the model's representation of the epidemic).  With these bands, we can compare \textit{models} to \textit{models} by assessing the distance between the two bands of model representation. We recommend using the Hausdorff distance to compare two bands to one another, as this distance captures how much bigger the sets would have to expand to cover each other.  The Hausdorff distance is defined mathematically as 
\[
d_\text{Hausdorff}(S_1, S_2) = \max \left\{ \sup_{x \in S_1} \inf_{y \in S_2} d(x,y),\; \sup_{y \in S_2} \inf_{x \in S_1} d(x,y)\right\}\;.
\]

# Overview of \pkg{EpiCompare} {short-title="Package overview" #sec:overview}

\ben{**The goals of this section is to present parts of the data science pipeline, introduce how we help, why they are useful and the ideas behind it.**}

In this section, we present the tools implemented in \pkg{EpiCompare} and explain how they aid in the  data analysis pipeline.  In Fig. \ref{fig:pipeline2}, we illustrate how our package fits into the data analysis pipeline introduced in Fig. \ref{fig:pipeline}.  All front-facing functions are aimed to be as user-friendly as possible, and we focus on providing the user "tidyverse" style functions, that encourage piping and also follow clear verb naming schemes \citep{Wickham2019}. Although users can typically incorporate \pkg{EpiCompare} into any step in the data analysis process, there are two primary points of entry.  The first point of entry is the very beginning with pre-processing and visualizing raw data, and the second point of entry is after modeling and simulation. Figure \ref{fig:pipeline2} captures these different paths, and we will highlight both approaches and how to leverage \pkg{EpiCompare} in the subsections below.

\begin{sidewaysfigure}[!ht]
    \centering
    \includegraphics[width = 1\textwidth]{images/pipeline2.png}
    \caption{How \pkg{EpiCompare} supplements and aids in the epidemiological data analysis pipeline.}
    \label{fig:pipeline2}
\end{sidewaysfigure}


**Data Pre-processing**

The first step of most data analysis is cleaning up the data to be explored. There are multiple ways to collect the epidemiological data. Sometimes individual records with times of different states of the epidemic (infection, recovery, etc.) as well as individual information like network structure, location, and sub-population information will be collected, whereas other data collections will focus on aggregate counts of individuals in each epidemic state.  In fact, usually only the number of new infections at each time step is observed and the compartment totals are then imputed from that along with other information about the disease and the population of interest.  We focus on understanding the overall impact of an outbreak at the aggregate/population level.  In \pkg{EpiCompare}, we provide a function to transform information about each individual/agentâ€™s initial time of entry into each state (e.g. start of infection, start of recovery, etc). This transformation between \textit{agent} information to \textit{aggregate} information is useful for seeing the overall trend of the epidemic (and how it impacts different subpopulations). Our tools allow the user to easily group agents and define new subpopulations to explore. This is important as case studies highlight the usefulness of identifying differing subpopulations (e.g. age, sex) and many state based models provide for subpopulation-based states in their analysis \citep{rvachev1985,anderson1992,worby2015}. 

We provide a "tidyverse"-styled function, `agents_to_aggregate()` to transform agent information into aggregate state information.  As a "tidy" function, our function `agents_to_aggregate()` allows the user to identify and analyze subpopulations by first executing a `group_by()` from \pkg{dplyr}. The function `agents_to_aggregate` is flexible in that there is no limit on the amount of permitted epidemiological states so users can incorporate information from compartments such as "Exposed", "iMmune", or "Hospitalized" groups, for instance, and also permits indicators for death/exit and birth/entry dates. Our function, `agents_to_aggregate()` does not require agents to pass through every state listed and agents are allowed to start in any state. This function is constrained to integer time steps (for example days), but transformations (linear or otherwise) of the time columns can account for finer grained time steps (e.g. hours or minutes). The function `agents_to_aggregate()` returns the total number of individuals in each state at each time point.  We view `agents_to_aggregate()` as powerful tool in the step of pre-processing data, one that quickly and simply transforms individual level information into an aggregate view that can be processed and analyzed in a simpler manner.

**EDA**

With raw data,  exploratory analysis frequently means figuring out good combinations of visualizations, numerical summaries, and groupings. An expert coder can start from `agents_to_aggregate()` to successfully accomplish EDA in many ways, but we have also developed tools to allow a novice coder to rapidly explore data, as long as there three unique epidemiological states (like the SIR model). Our `geom_aggregate()` provides a rapid way to explore different subpopulations' experiences of the epidemic in the ternary lens. It combines the ideas behind `agents_to_aggregate()` with \pkg{ggplot2}'s `geom_path()` and \pkg{ggtern}'s `coord_tern()` to visualize any number of groups epidemic trajectory in 3d simplex \citep{Wickham2016, Hamilton2018}. We developed these out-of-the-box visualization tools for SIR models because (1) SIR models are some of the most common and basic epidemic state-based models and (2) our simplex representation of these epidemics emphasizes a "time-invarance" representation of the data (see Section \ref{sec:time-invariant}).

**Model Fitting and Simulations**

Although this package does not focus on estimating a model for the data, we do provide some flexible functions for simulation of basic discrete-time epidemic-state models with Bernoulli/Multinomial transitions which can be used to (noisily) approximate ODEs which describe transitions from one state to the next.  These functions can be naturally combined with `agents_to_aggregate()` to proceed in the pipeline.  The function `simulate_SIR_agents()` simulates an SIR epidemic with user inputs for the number of simulations, the initial number in each state, the infection and recovery parameters $(\beta, \gamma$), and the total number of discrete time steps.  This function allows for easy access to SIR model analysis and comparison.  Beyond SIR models, the function `simulate_agents()` takes as input a user-specified transition matrix and other epidemic parameters to allow the user to create simulations of an outbreak for \textit{any} number of states and any number of transitions among them.  This allows for users to explore the space of models in an intuitive way without getting bogged down by too much mathematical detail. For consistency, we have made output from `simulate_agents()` and `simulate_SIR_agents()` compatible with `agents_to_aggregate()` so aggregate information may easily be accessed.


**Post-processing**

Post-processing of modeling and simulation consists of making summary statistics, plots, tables, and other ways to disseminate information to the public.  For example, comma separated value files (`.csv`) are a  standard way to share information within tables.  However, model output is often far more complicated than what a traditional `.csv` would allow.  As a result, a number of epidemic modeling packages return a special class, specific to their modeling.  The special classes often contain a plethora of information from residuals, model diagnostics, input parameters, and more.  While incredibly useful, these special classes can be difficult for novice coders to navigate. 

To this end, we have adapted a series of `fortify`-style functions, called `fortify_aggregate()` which transform output from packages like \pkg{pomp} and \pkg{EpiModel} into tidy-styled data frames which contain information about the total number of individuals in each state at a given time, for a given simulation.  These fortify functions have output that is consistent with that of `agents_to_aggregate()`.

\shannon{Here Ben talks about filament compression and tidy_dist mats, etc}




**Comparisons and Assessment**

Comparison and assessment of model fit or comparisons of one model to another model can be performed in a variety of ways including mean square error, AIC, plots, and more.  Perhaps the most useful tool \pkg{EpiCompare} has to offer to the expert, for comparison and assessment of models, is in its post-processing tools which create a standard output.  It is then a matter of writing a script or function made for that standard output to assess the results from multiple models in the way the user desires.

However, for those who like more concrete tools, \pkg{EpiCompare} offers functions to compare prediction regions to one another including `geom_prediction_band()` (which plots the region), and `create_{convex_hull,delta_ball}_structure()`(which returns the `R` output for the given structure), and `contained()` (which allows the user to determine if one set of points is contained in a prediction band).  Additionally, we offer ways to determine if model outputs are compatible with one another, that is how extreme one output is to another.  \shannon{Ben says something about distance}


# A tour of \pkg{EpiCompare} {short-title="Tour" #sec:tour}



In this section, we highlight a number of the functionalities available in \pkg{EpiCompare}.  These functionalities include data cleaning, visualization, simulation, and comparison, in accordance with the data analysis pipeline \ref{fig:pipeline}. We show a full data analysis from beginning to end that can be accomplished in a streamlined and standardized manner.


\subsection{Data and exploratory analysis}

We analyze an outbreak of measles in the town of Hagelloch, Germany from 1861-1862, a data set organized by \cite{pfeilsticker1863}.  The data was later made visible by \cite{oesterle1992} and made available in an \proglang{R} by \cite{surveillance2017}.  The Hagelloch data includes a rich set of features including household members, school level, household locations, date of first symptoms (prodromes), date of measles rash, and even the alleged infector. A subset of the data is shown in Table \ref{tab:hags-people}.   Because of these rich features, this data set has been an ideal testing ground  methodology in infectious disease epidemiology and is used in work by \cite{Neal2004,britton2011,groendyke2012,becker2016}.







```{r hagelloch-subset-view, echo = FALSE}
hagelloch_raw %>% select(PN, HN, NAME, AGE, SEX, CL,  PRO, ERU, IFTO) %>%
  filter(PN %in% paste(c(1:5, 45))) %>% kable(format = "latex", booktabs = TRUE, caption = "Subset of Hagelloch infection data.  Features include the person ID, household ID (HH ID), age, sex, class level (Pre-K/1st/2nd), date of first symptoms, date of the appearance of the measles rash, and the alleged infector ID of the individual.",
                                              linesep = "",
                    col.names = c("ID","HH ID", "Name", "Age", "Sex", 
                                  "Class", "Symp. Start", "Rash Date", "Infector ID"),
                    label = "hags-people") %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

With \pkg{EpiCompare}, we can easily obtain the empirical cumulative incidence function with respect to the measles rash appearance (variable \code{ERU}) with the following tidy-style function, \code{agents_to_aggregate}.  The function \code{agents_to_aggregate} is a key component of \pkg{EpiCompare}, allowing the user to easily switch from an individual-level (i.e. an agent) view of a disease to an aggregate level.  For example, the below code shows how we can convert the agent data to a cumulative incidence of the measles rash, in order to see how the disease spread through the population over time. We can then compare the cumulative incidence of the rash to the cumulative incidence of the prodromes, i.e. the initial symptoms.  We do this with the below code, and a part of the cumulative incidence data output are shown in Table \ref{tab:cif-rash}.  The argument \code{integer_time_expansion} indicates whether we should include all time points in the recorded range of the data or only when there is a change in the incidence.

```{r }
cif_rash  <- hagelloch_raw %>%
  mutate(time_of_rash = as.numeric(ERU - min(PRO, na.rm = TRUE))) %>%
  agents_to_aggregate(states = time_of_rash,
                      integer_time_expansion = FALSE) %>%
  mutate(type = "Rash")
```


```{r echo = FALSE}
cif_rash %>% 
  dplyr::select(-type) %>%
  head(5) %>% kable(booktabs = TRUE,
                               caption = "Turning the individual-level information from the Hagelloch data to an aggregate view of the cumulative incidence of the measles rash in the population over time.",
                               label = "cif-rash",
                              col.names = c("Time", "# Susceptible", "# Total rash appearances") ) %>%
  kable_styling(position = "center", 
                latex_options = "hold_position"
                      )
```


One question of interest is the duration between initial onset of prodromes or symptoms and the appearance of the measles rash.  Since \code{agent_to_aggregate} outputs a tidy-style data frame, it is a simple task to plot the two sets of incidence curves on the same graph (Fig. \ref{fig:cifs}).





```{r}
cif_prodromes <- hagelloch_raw %>%
  mutate(time_of_PRO = as.numeric(PRO - min(PRO, na.rm = TRUE))) %>%
  agents_to_aggregate(states = time_of_PRO,
                      integer_time_expansion = FALSE) %>%
  mutate(type = "Pro")
```



```{r fig.cap = "\\label{fig:cifs}Empirical cumulative incidence functions of prodrome (symptom) onset and measles rash appearance.  We see that there is approximately a a constant lag between the two curves."}
plot_df <- bind_rows(cif_rash, cif_prodromes)

ggplot(data = plot_df,
       aes(x = t, y = X1, col = type)) + 
  geom_step() + 
  labs(title = "Cumulative incidence of measles appearance",
       x = "Time (days relative to first prodrome appearance)",
       y = "Cumulative incidence of event") + 
  coord_cartesian(xlim = c(0, 55)) +
  scale_color_manual(values = c("blue", "red"))

```


```{r echo = FALSE, results = 'hide'}
data(hagelloch_raw)
with(hagelloch_raw, sum(PRO > ERU, na.rm = TRUE))

```

The real power of \code{agents_to_aggregate()} lies in its ability to aggregate over any number of pre-specified states.  For example, the Hagelloch data sets contains two columns, \code{tI} and \code{tR}, the time of infection and recovery, respectively of each individual.  We can then plot the SIR values through a time-invariant lens using \pkg{ggplot2} and \pkg{ggtern} functions (as shown in Fig. \ref{fig:hag-tern-raw}) or with our custom \code{geom}, \code{geom_aggregate}, which takes the raw agent data as input.

```{r fig.cap = "\\label{fig:hag-tern-raw}Time invariant view of the Hagelloch epidemic where we view the individuals in Susceptible, Infectious, or Recovered states.  We see there are two peaks of infection (the vertical axis)."}
hagelloch_sir <- hagelloch_raw %>%
  agents_to_aggregate(states = c(tI, tR),
                      min_max_time = c(0, 55)) %>%
  rename(time = t, S = X0, I = X1, R = X2)


ggplot(hagelloch_sir, aes(x = S, y = I, z = R))+
  coord_tern() +
  geom_path() +
  labs(x = "S", y = "I", z = "R",
       title = "Time invariant view of Hagelloch measles outbreak") + 
  theme_sir(base_size = 24)

```

Moreover, we can look at the outbreaks of the disease by group within \code{agent_to_aggregate()} or \code{geom_aggregate()}.  This allows us to examine differences among the different groups of individuals.  For example, we show the time invariant outbreak by class level in Figure \ref{fig:tern-class-data}.  Immediately, we see that time invariant infection curve is different for the pre-school class compared to the 1st class.  In the 1st class, we see about 95\% of the class become infected and less than 10\% of them having recovered, which is indicative of a super-spreading event.  This suspicion is further confirmed in that `r max(table(hagelloch_raw$IFTO[hagelloch_raw$CL == "1st class"]))` of the `r nrow(hagelloch_raw[hagelloch_raw$CL == "1st class",])` 1st class students have been reportedly infected by the same individual.

```{r fig.cap = "\\label{fig:tern-class-data}Time invariant outbreak curves for the three class groups.  The pre-school class has a distinct peak of infection whereas the peak infection point for the other two classes are less well defined."}
hagelloch_raw %>%
  ggplot(aes(y = tI, z = tR, color = CL)) +
  geom_aggregate(size = 2) + coord_tern() +
  labs(x = "S", y = "I", z = "R",
       color = "Class") +
  scale_color_brewer(palette = "Dark2") +
  facet_wrap(~CL)
```

Along with multiple epidemic states, the function \code{agents_to_aggregate} can also be extended to populations with vital dynamics (e.g. birth and death) and examples of this are shown in the package vignette.  In summary, \code{agents_to_aggregate()} is a multi-purpose workhorse that may be leveraged to convert individual level records into aggregate information that may be more useful for some forms of epidemic modeling such as compartment modeling.

Up to this point, we have used \pkg{EpiCompare} in the context of observed data.  We also want to compare statistical models, and \pkg{EpiCompare} aids in that process via a simple but dynamic individual-level data generator, conversion tools for popular epidemic model packages, and model assessments.  We demonstrate an example here.

We first try to model the Hagelloch data with a stochastic SIR model, which we refer to as the 'simple SIR.'  In our vignette, we show how to fit this simple SIR model via maximum likelihood and simulate from the model with those best fit parameters.  Our function \code{simulate_agents()} generates individual level data according to discrete time multinomial draws, which depend on the number of individuals in each state at the previous time step and a matrix of transition probabilities.  For example, the below code generates 100 simulations of an outbreak of a disease with one initial infector in a population of $n= 188$ individuals.


```{r}
trans_mat <- matrix(c("X0 * (1 - X1 * par1 / N)", "X0 * X1  * par1 / N", "0",
                  "0", "X1 * (1 - par2)", "par2 * X1",
                  "0", "0", "X2"), byrow = TRUE, nrow = 3)
```



```{r cache = TRUE}
set.seed(2020)

best_params <- c("beta" = .36, "gamma" = .13)
## This is the SIR representation

rownames(trans_mat) <- c("S", "I", "R")
init_vals <- c(187, 1, 0)
par_vals <- c(par1 = best_params[1], par2 = best_params[2])
max_T <- 55
n_sims <- 100

agents <- simulate_agents(trans_mat,
                       init_vals,
                       par_vals,
                       max_T,
                       n_sims,
                       verbose = FALSE)


```
```{r}
agg_model <- agents %>% group_by(sim) %>%
  agents_to_aggregate(states = c(I, R)) %>%
  mutate(Type = "Simple SIR")
```
The result of our simulation is the object \code{agents} which is a `r nrow(agents)` $\times$ `r ncol(agents)` data frame, which details the time of entry into the $S$, $I$, and $R$ states for a given simulation.  Before we examine the results of this simple SIR model, we will also examine another, more sophisticated SIR model, this time from the package \pkg{EpiModel}.  Briefly, this model first fits a contact network to the set of indivduals, where the class of the student is a covariate.  The model then simulates a SIR-epidemic on that network.

```{r cache = TRUE, results = 'hide'}
library(EpiModel)
## WARNING:  Will take a minute or two

set.seed(42)
nw <- network.initialize(n = 188, directed = FALSE)
nw <- set.vertex.attribute(nw, "group", rep(0:2, each = 90, 30, 68))
formation <- ~edges + nodematch("group") + concurrent
target.stats <- c(200, 300, 200)
coef.diss <- dissolution_coefs(dissolution = ~offset(edges),  duration = 5)
est1 <- netest(nw, formation, target.stats, coef.diss, edapprox = TRUE)

param <- param.net(inf.prob = 0.1, act.rate = 5, rec.rate = 0.1)
status.vector <- c(rep(0, 90), rep(0, 30), rep(0, 67), 1)
status.vector <- ifelse(status.vector == 1, "i", "s")
init <- init.net(status.vector = status.vector)
control <- control.net(type = "SIR", nsteps = 55,
                       nsims = 100, epi.by = "group")
epimodel_sir <- netsim(est1, param, init, control)

```


The output of this model is \code{epimodel_sir}, an object of class \code{`r class(epimodel_sir)`}, which contains a plethora of modeling information.  We provide the function \code{fortify_aggregate()}, which can take objects from specialized classes of modeling output and transform it into a tidy-style data frame.

```{r}
fortified_net <- fortify_aggregate(epimodel_sir, 
                                   states = c("s.num", "i.num", "r.num")) %>%
  mutate(Type = "EpiModel SIR",
         sim = as.numeric(gsub("sim", "", sim)))
```


We can then analyze the results of the two models side by side as time-invariant epidemic curves.  The results are shown in Figure \ref{fig:hag-simple-sir}, where a 90\% prediction band is estimated from the delta ball method for each of the two models.  For the Simple SIR model, we see that the data generally covers the data fairly well but clearly misses the second peak of infection.  We also see that the prediction band is very large, covering up a large area of the ternary plot.  On the other hand, for the \pkg{EpiModel} model, we see that the prediction band covers the data quite well and takes up less area.



```{r cache = TRUE}

both_models <- bind_rows(agg_model, fortified_net)


g <- ggplot() + geom_prediction_band(data = both_models %>% filter(t != 0),
         aes(x = X0, y = X1, z = X2,
              sim_group = sim, fill = Type),
         alpha = .5,
         conf_level = .90) 
```

```{r , fig.cap = "\\label{fig:hag-simple-sir}  Original Hagelloch SIR data (black) along with 90\\% prediction band and actual simulation paths from the Simple SIR and the EpiModel SIR models."}
g +   geom_path(data = both_models %>% filter(t !=0),
            aes(x = X0, y = X1, z = X2, group = paste(Type, sim)),
            alpha = .3, col = "gray40") + 
    coord_tern() + theme_sir(base_size = 24) +
  geom_point(data = hagelloch_sir,
             aes(x = S, y = I, z =R), col = "black") +
  labs(title = "Simple SIR model",
       subtitle = "90% Prediction band and original data",
       x = "S", y = "I", z = "R") +
  scale_fill_manual(values = c("#006677", "#AA6600")) + 
  facet_wrap(~Type) +
  theme(legend.position = "bottom")
     
```

However, both models are not a good fit to the filamental path as opposed to the individual points in $(S, I, R)$-space.  This can be captures with the set of simulations both models predict, which all generally have a single defined peak of infection whereas the data certainly looks like it has two distinct peaks, likely caused by our assumed super-spreader event.  This observation is backed up by the below analysis that demonstrates that the estimated psuedo-density of the observed epidemic (relative to the simulations from either model) is much less likely then **any** of the simulations (reported in Table \ref{tab:hags-extreme}. In conclusion, \pkg{EpiCompare} makes it clear that, at a glance, 1) the EpiModel network model is a better fit than the Simple SIR model, and 2) the fit is only good at the individual point level as opposed to the epidemic path level.


```{r echo = F}
simple_sir <- both_models %>% filter(Type == "Simple SIR") %>%
  rename(S = "X0", I = "X1", R = "X2") %>%
  select(Type, sim, t, S, I, R)

hagelloch_sir2 <- hagelloch_sir %>%
  rename(t = "time") %>%
  mutate(Type = "true observation",
         sim = 0) %>%
  select(Type, sim, t, S, I, R)
```
```{r}
#-- after cleaning up and combining --
all_together_df <- rbind(simple_sir,
                         hagelloch_sir2)
```

```{r echo = F}
all_together_df[c(1:2, nrow(all_together_df) - c(1:0)),] %>% 
  kable(booktabs = TRUE,
        caption = paste("Top and bottom 2 rows of \\tt{all\\_together\\_df}\\text{,",
                        "combining both simulated epidemics and the true",
                        "epidemic.}"), label = "cif-all-together-df") %>%
  kable_styling(position = "center", 
                latex_options = "hold_position"
                      )
```

```{r}
compression_df <- all_together_df %>% group_by(Type, sim) %>% 
  filament_compression(data_columns = c("S","I","R"), 
                       number_points = 20)
```

```{r echo = F}
# # -OR- for 2d onto the simplex (done under the hood in geom_prediction_band:
# compression_df <- all_together_df %>% 
#   as.data.frame() %>% # just to be sure...
#   get_xy_coord(xyz_col = c("S", "I", "R")) %>% # to 2d simplex space
#   group_by(Type, sim) %>%
#   filament_compression(data_columns = c("x","y"), 
#                        number_points = 20)

```

```{r}
tdmat <- compression_df %>% 
  dist_matrix_innersq_direction(
    position = c(1:length(compression_df))[
      names(compression_df) %in% c("S","I", "R")],
    tdm_out = T)

simple_sir_true_obs_info <- tdmat %>% 
  compare_new_to_rest_via_distance(
    new_name_id = data.frame(Type = "true observation", sim = 0),
    distance_func = distance_psuedo_density_function, 
    sigma = "20%") 

```

```{r echo = F}
# EpiModel simulations:
epimodel_sir <- both_models %>% filter(Type == "EpiModel SIR") %>%
  rename(S = "X0", I = "X1", R = "X2") %>%
  select(Type, sim, t, S, I, R)

hagelloch_sir2 <- hagelloch_sir %>%
  rename(t = "time") %>%
  mutate(Type = "true observation",
         sim = 0) %>%
  select(Type, sim, t, S, I, R)

all_together_df <- rbind(epimodel_sir,
                         hagelloch_sir2)

compression_df <- all_together_df %>% group_by(Type, sim) %>% 
  filament_compression(data_columns = c("S","I","R"), 
                       number_points = 20)

tdmat <- compression_df %>% 
  dist_matrix_innersq_direction(
    position = c(1:length(compression_df))[
      names(compression_df) %in% c("S","I", "R")],
    tdm_out = T)

epimodel_sir_true_obs_info <- tdmat %>% 
  compare_new_to_rest_via_distance(
    new_name_id = data.frame(Type = "true observation", sim = 0),
    distance_func = distance_psuedo_density_function, 
    sigma = "20%") 
```

```{r hagelloch-extremeness, echo = FALSE}
simple_sir_info <- simple_sir_true_obs_info %>%
  select(-sim) %>%
  mutate(Type = "Simple SIR")
eimodel_sir_info <- epimodel_sir_true_obs_info %>%
  select(-sim) %>%
  mutate(Type = "EpiModel SIR")

rbind(simple_sir_info, eimodel_sir_info)  %>%
  kable(format = "latex", booktabs = TRUE, 
        col.names = 
          linebreak(c("Type",
                      "simulations-based estimated psuedo-density",
              "proportion of simulations with lower estimated psuedo-density"),
              align = c("l")),
        caption = paste("The extremeness of the true simulations based on",
                        "comparing psuedo-density estimates between true",
                        "vs simulated curves"), label = "hags-extreme") %>%
  kable_styling(position = "center", latex_options = "hold_position") %>%
  column_spec(2:3, width = "6cm")
```



# A. Appendix {-}

## A.1 Proof of Theorem \ref{thm:sir-scale} {-}

\begin{proof}\label{proof:thm}
\cite{Harko2014} provide an analytical solution for the Kermack and McKendrick equations (Eq. \eqref{eq:sir-ode}) by reparameterizing the ODEs so that $\mathcal{S}(u) = S(t)$, $\mathcal{I}(u) = S(t)$, and $\mathcal{R}(u) = R(t)$ for $0< u_T < 1$ with
\begin{align}\label{eq:harko-odes}
\mathcal{S}(u) &= S(0)u\\
\mathcal{I}(u) &= N - R(0) + NR_0^{-1}\log u - S(0)u \nonumber\\
\mathcal{R}(u) &= R(0) - NR_0^{-1} \log u, \nonumber
\end{align}
and $u$ and t are related by the following integral,
\begin{align*}
    t &= \int_{u}^1 \frac{N}{\beta \tau (N - R(0) + R_{0}^{-1} \log \tau - S(0)\tau)}d\tau \\
    &= \int_{u}^1 \frac{1}{\beta f(S(0), R(0), N, R_0, \tau)} d \tau\\
    &= \int_{u}^1 \frac{1}{\beta f(\tau)} d\tau,
\end{align*}
where we have made the denominator of the integral a function of $N$, the initial values, $R_0$, and $\tau$, which we further condense to $f(\tau)$ for brevity.
Then for a given $t$ we want to find $s$ such that $(S_1(t), I_1(t), R_1(t)) = (S_2(s), I_2(s), R_2(s))$.  Or equivalently, for a fixed $u$ want to find $v$ such that  $\mathcal{S}_1(u) = \mathcal{S}_2(v)$ and then the corresponding $t$ and $s$ are given by
\begin{align*}
    t & = \int_{u}^1 \frac{1}{\beta_1 f(\tau)} d\tau \\
    s & = \int_{v}^1 \frac{1}{\beta_2 f(\tau)} d\tau.
\end{align*}
Note that since the equations in Eq. \eqref{eq:harko-odes} are functions of the initial values and $R_0$, then $u = v$. We then can find a relation for $s$,
    \begin{align*}
    s & = \int_{u}^1 \frac{1}{\beta_2 f(\tau)} d\tau  \\
    & = \int_{u}^1 \frac{1}{a\beta_1 f(\tau)} d\tau \\ 
    &= \frac{1}{a}\int_{u}^1 \frac{1}{\beta_1 f(\tau)} d\tau \\
    &= \frac{1}{a}t.
\end{align*}
\end{proof}





